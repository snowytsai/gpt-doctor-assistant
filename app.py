import streamlit as st
import openai
import tiktoken

# è«‹æ›¿æ›æˆä½ è‡ªå·±çš„ OpenAI API Key
openai.api_key = "ä½ çš„APIé‡‘é‘°"

# Streamlit æ¨™é¡Œ
st.title("é†«å¸« GPT å•è¨ºåŠ©ç†")

# ä½¿ç”¨è€…è¼¸å…¥ï¼ˆç—…æ‚£ä¸»è¨´ + é†«ç—…å°è©±ï¼‰
system_prompt = "ä½ æ˜¯ä¸€ä½å…§ç§‘é†«å¸«åŠ©ç†ï¼Œè«‹æ ¹æ“šç—…æ‚£ä¸»è¨´èˆ‡å°è©±ï¼Œæä¾›çµ¦é†«å¸«å»ºè­°ï¼šå¯èƒ½è¨ºæ–·ã€æ‡‰è¿½å•çš„å•é¡Œã€å»ºè­°æª¢æŸ¥èˆ‡æ²»ç™‚æ–¹æ¡ˆã€‚"

user_input = st.text_area("è«‹è¼¸å…¥ç—…æ‚£ä¸»è¨´èˆ‡å°è©±ï¼š", height=200)

if st.button("ç”Ÿæˆå»ºè­°"):
    if user_input:
        with st.spinner("GPT ç”Ÿæˆä¸­..."):
            # è¨ˆç®— Token
            encoding = tiktoken.encoding_for_model("gpt-4")
            input_tokens = len(encoding.encode(system_prompt + user_input))

            # å‘¼å« GPT
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                max_tokens=500,
                temperature=0.5
            )

            reply = response['choices'][0]['message']['content']
            output_tokens = response['usage']['completion_tokens']
            total_tokens = response['usage']['total_tokens']

            st.subheader("GPT å»ºè­°ï¼š")
            st.write(reply)

            # æˆæœ¬è¨ˆç®—
            input_cost = input_tokens / 1000 * 0.01
            output_cost = output_tokens / 1000 * 0.03
            total_cost = input_cost + output_cost

            st.info(f"è¼¸å…¥ Tokenï¼š{input_tokens}ï¼Œè¼¸å‡º Tokenï¼š{output_tokens}")
            st.success(f"ä¼°ç®—è²»ç”¨ï¼šç´„ ${total_cost:.4f} ç¾å…ƒ")

from streamlit_audiorecorder import audiorecorder
import tempfile
import base64

st.subheader("ğŸ™ï¸ éŒ„éŸ³è¼¸å…¥")

audio = audiorecorder("é»æˆ‘é–‹å§‹éŒ„éŸ³", "éŒ„éŸ³ä¸­...")

if len(audio) > 0:
    st.audio(audio.export().read(), format="audio/wav")

    # å°‡éŒ„éŸ³å¯«å…¥æš«å­˜æª”
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        audio.export(tmp_file.name, format="wav")
        audio_path = tmp_file.name

    st.info("âœ… éŒ„éŸ³å®Œæˆï¼Œé–‹å§‹è½‰æ–‡å­—...")

    import openai
    openai.api_key = "ä½ çš„APIé‡‘é‘°"

    # ä½¿ç”¨ Whisper å°‡èªéŸ³è½‰æˆæ–‡å­—
    with open(audio_path, "rb") as f:
        transcript = openai.Audio.transcribe("whisper-1", f)

    st.success("èªéŸ³è½‰æ–‡å­—çµæœï¼š")
    st.write(transcript["text"])
    
    # è‡ªå‹•å¡«å…¥ä¸»è¨´æ¬„ä½ï¼ˆå¯é¸ï¼‰
    user_input = transcript["text"]
